% Encoding: UTF-8

@InProceedings{,
  author = {José L. Abellán , Juan Fernández, Manuel E. Acacio},
  title  = {Efficient Hardware-Supported Synchronization Mechanisms for Manycores},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_bc15.pdf:PDF},
}

@Misc{,
  author   = {José L. Abellán, Juan Fernández, Manuel E. Acacio},
  title    = {Efficient and scalable barrier synchronization for many-core CMPs},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_cf10.pdf:PDF},
  keywords = {g-line-based barrier synchronization, global interconnection lines, many-core cmps, s-csma technique},
}

@InProceedings{Bladespp.,
  author    = {Blades},
  booktitle = {ICCS 2008},
  title     = {Characterizing the Basic Synchronization and Communication Operations in Dual Cell-Based},
  year      = {pp.},
  editor    = {M. Bubak and others},
  pages     = {5101},
  publisher = {Springer},
  series    = {Part},
  volume    = {I},
  abstract  = {The Cell Broadband Engine (Cell BE) is a heterogeneous
chip-multiprocessor (CMP) architecture to offer very high performance,
especially on game and multimedia applications. The singularity of its
architecture, nine cores of two different types, along with the variety of
synchronization and communication primitives offered to programmers,
make the task of developing efficient applications very challenging. This
situation gets even worse when we consider Dual Cell-Based Blade ar-
chitectures where two separate Cells can be linked together through a
dedicated high-speed interface. In this work, we present a characteriza-
tion of the main synchronization and communication primitives provided
by dual Cell-based blades under varying workloads. In particular, we fo-
cus on the DMA transfer mechanism, the mailboxes, the signals, the
read-modify-write atomic operations, and the time taken by thread cre-
ation. Our performance results expose the bottlenecks and asymmetries
of these platforms which must be taken into account by programmers for
improving the efficiency of their applications.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_iccs08.pdf:PDF},
}

@InProceedings{Procedia1877,
  author   = {Procedia and Computer Science and and ( and ) and 2545 and 2548},
  title    = {Available online at www.sciencedirect.com},
  year     = {1877},
  doi      = {1},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_iccs13.pdf:PDF},
  keywords = {Many-Core CMPs, Cache Coherence, G-Lines Technology},
}

@Misc{Abellan,
  author   = {José L. Abellán, Juan Fernández, Manuel E. Acacio},
  title    = {A G-Line-Based Network for Fast and Efficient Barrier Synchronization in Many-Core CMPs},
  abstract = {2010 39th International Conference on Parallel Processing},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_icpp10.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_ina10.pdf:PDF},
}

@Misc{Abellana,
  author   = {José L. Abellán, Juan Fernández, Manuel E. Acacio},
  title    = {GLocks: Efficient Support for Highly-Contended Locks in Many-Core CMPs},
  abstract = {2011 IEEE International Parallel & Distributed Processing Symposium},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_ipdps11.pdf:PDF},
}

@Article{Abellan2009,
  author    = {Jos{\'{e}} L. Abell{\'{a}}n and Juan Fern{\'{a}}ndez and Manuel E. Acacio},
  journal   = {The Journal of Supercomputing},
  title     = {Characterizing the basic synchronization and communication operations in Dual Cell-based Blades through {CellStats}},
  year      = {2009},
  month     = {apr},
  number    = {2},
  pages     = {247--268},
  volume    = {53},
  doi       = {10.1007/s11227-009-0292-7},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_jsc10.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Abellan2008,
  author    = {Jose L. Abellan and Juan Fernandez and Manuel E. Acacio},
  booktitle = {16th Euromicro Conference on Parallel, Distributed and Network-Based Processing ({PDP} 2008)},
  title     = {{CellStats}: A Tool to Evaluate the Basic Synchronization and Communication Operations of the Cell {BE}},
  year      = {2008},
  month     = {feb},
  publisher = {{IEEE}},
  doi       = {10.1109/pdp.2008.49},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_pdp08.pdf:PDF},
}

@Misc{,
  title = {samos13.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/abellan_samos13.pdf:PDF},
}

@Misc{,
  title = {PII: S0167-739X(01)00054-1},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_fgcs02.pdf:PDF},
}

@InProceedings{Acacio7695,
  author    = {Manuel E. Acacio and José González and José M. García José Duato and Dpto. Ing. y Tecnología and de Computadores and Dpto. Inf. de Sistemas and y Computadores},
  booktitle = {Proceedings of the Seventh International Symposium on High-Performance Computer Architecture (HPCA01)},
  title     = {A New Scalable Directory Architecture for Large-Scale Multiprocessors},
  year      = {7695},
  publisher = {IEEE},
  abstract  = {memory paradigm have limited scalability, thus becom-
ing unfeasible for very large-scale systems, which use the},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_hpca01.pdf:PDF},
}

@InProceedings{Acacio1530,
  author    = {Manuel E. Acacio and José González and José M. Garcı́a José Duato and Dpto. Ing. y Tecnologı́a and de Computadores and Dpto. Inf. de Sistemas and y Computadores},
  booktitle = {Proceedings of the International Parallel and Distributed Processing Symposium (IPDPS02)},
  title     = {A Novel Approach to Reduce L2 Miss Latency in Shared-Memory Multiprocessors},
  year      = {1530},
  publisher = {IEEE},
  abstract  = {Address In},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_ipdps02.pdf:PDF},
}

@InProceedings{Acacio2002,
  author    = {Manuel E. Acacio and José Gonzálezy and José M. Garcı́a and José Duatoz},
  booktitle = {Proceedings of the 2002 International Conference on Parallel Architectures and Compilation Techniques (PACT’02)},
  title     = {The Use of Prediction for Accelerating Upgrade Misses in cc-NUMA Multiprocessors},
  year      = {2002},
  publisher = {IEEE},
  abstract  = {Even with non-blocking caches and out-of-order proces-
sors, previous studies have shown that the relatively long},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_pact02.pdf:PDF},
}

@Misc{Acacio,
  author = {Manuel E. Acacio, Jose Gonzalez, Jose M. Garcia, Jose Duato},
  title  = {Reducing the Latency of L2 Misses in Shared-Memory Multiprocessors through On-Chip Directory Integration},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_pdp05.pdf:PDF},
}

@InProceedings{Acacio7695a,
  author    = {Manuel E. Acacio and José González and José M. Garcı́a and José Duato},
  title     = {Owner Prediction for Accelerating Cache-to-Cache Transfer Misses in a cc-NUMA Architecture},
  year      = {7695},
  publisher = {IEEE},
  abstract  = {sors, previous studies have shown that the relatively long
L2 miss latency found in cc-NUMA multiprocessors con-},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_sc02.pdf:PDF},
}

@InProceedings{Architecture2004,
  author    = {An Architecture and for High-Performance and Scalable and Shared-Memory Multiprocessors and Exploiting},
  title     = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 15, NO. 8, AUGUST},
  year      = {2004},
  publisher = {IEEE},
  abstract  = {Recent technology improvements allow multiprocessor designers to put some key components inside the processor chip,},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_tpds04.pdf:PDF},
}

@InProceedings{TwoLevel2005,
  author    = {A Two-Level and Directory Architecture and for and Highly Scalable and cc-NUMA Multiprocessors},
  title     = {IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 16, NO. 1, JANUARY},
  year      = {2005},
  publisher = {IEEE},
  abstract  = {One important issue the designer of a scalable shared-memory multiprocessor must deal with is the amount of extra},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_tpds05.pdf:PDF},
}

@Misc{,
  title = {Microsoft Word - 37400016.doc},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_acsac05.pdf:PDF},
}

@InProceedings{Luis1530,
  author    = {Juan Luis and Aragon Dan and Nicolaescu Alex and Veidenbaum Ana–Maria and Badulescu},
  title     = {Energy–Efficient Design for Highly Associative Instruction Caches in Next–Generation Embedded Processors},
  year      = {1530},
  publisher = {IEEE},
  abstract  = {instructions needed in a cycle as determined by issue width
N. Second, it further reduces the number of instructions read},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_date04.pdf:PDF},
}

@Misc{,
  author = {jlaragon},
  title  = {Microsoft Word - BPRU-HIPC-2001-FINAL.DOC},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_hipc01.pdf:PDF},
}

@InProceedings{Aragon1530,
  author    = {Juan L. Aragón and José González and Antonio González and 1Dept. Ing. y Tec. de Computadores and 2Intel Barcelona and Research Center and 3Dept. d’Arquitec. de Computadors},
  booktitle = {Proceedings of the The Ninth International Symposium on High-Performance Computer Architecture (HPCA-9’03)},
  title     = {Power-Aware Control Speculation through Selective Throttling},
  year      = {1530},
  publisher = {IEEE},
  abstract  = {stages in the Pentium 4 [12]). In these architectures, a
branch takes longer to be resolved and the processor is},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_hpca03.pdf:PDF},
}

@Misc{,
  author = {jlaragon},
  title  = {Microsoft Word - BPRU-ICCD-2001-FINAL.DOC},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_iccd01.pdf:PDF},
}

@Article{Aragon2008,
  author    = {Juan L. Arag{\'{o}}n and Alexander V. Veidenbaum},
  journal   = {Journal of Systems Architecture},
  title     = {Optimizing {CAM}-based instruction cache designs for low-power embedded systems},
  year      = {2008},
  month     = {dec},
  number    = {12},
  pages     = {1155--1163},
  volume    = {54},
  doi       = {10.1016/j.sysarc.2008.06.001},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_jsa08.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/aragon_tc06.pdf:PDF},
}

@Misc{,
  title = {articulo3.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_euromicro02.pdf:PDF},
}

@Misc{,
  title = {articulo.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_ispacs01.pdf:PDF},
}

@Misc{,
  title = {articulo.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_itab00.pdf:PDF},
}

@Misc{,
  title = {doi:10.1016/j.parco.2006.11.011},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_jpc07.pdf:PDF},
}

@Article{Bernabe2009,
  author    = {Gregorio Bernab{\'{e}} and Jose M. Garc{\'{\i}}a and Jos{\'{e}} Gonz{\'{a}}lez},
  journal   = {Journal of Systems and Software},
  title     = {A lossy 3D wavelet transform for high-quality compression of medical video},
  year      = {2009},
  month     = {mar},
  number    = {3},
  pages     = {526--534},
  volume    = {82},
  doi       = {10.1016/j.jss.2008.09.034},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_jss09.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Misc{,
  title = {articulo.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_mednet00.pdf:PDF},
}

@Misc{,
  title = {doi:10.1016/j.parco.2006.11.011},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_parco07.pdf:PDF},
}

@Misc{Bernabe,
  author = {Gregorio Bernabé},
  title  = {articulo2.dvi},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_pdp03.pdf:PDF},
}

@InProceedings{Reducing2005,
  author   = {Reducing 3D and Fast Wavelet and Transform Execution and Time Using and Blocking and the Streaming and SIMD Extensions},
  title    = {Journal of VLSI Signal Processing 41, 209–223, 2005 ©c 2005 Springer Science + Business Media, Inc. Manufactured in The Netherlands},
  year     = {2005},
  abstract = {The video compression algorithms based on the 3D wavelet transform obtain excellent compression
rates at the expense of huge memory requirements, that drastically affects the execution time of such applications. Its
objective is to allow the real-time video compression based on the 3D fast wavelet transform. We show the hardware
and software interaction for this multimedia application on a general-purpose processor. First, we mitigate the
memory problem by exploiting the memory hierarchy of the processor using several techniques. As for instance,
we implement and evaluate the blocking technique. We present two blocking approaches in particular: cube and
rectangular, both of which differ in the way the original working set is divided. We also put forward the reuse of
previous computations in order to decrease the number of memory accesses and floating point operations. Afterwards,
we present several optimizations that cannot be applied by the compiler due to the characteristics of the algorithm.
On the one hand, the Streaming SIMD Extensions (SSE) are used for some of the dimensions of the sequence (y
and time), to reduce the number of floating point instructions, exploiting Data Level Parallelism. Then, we apply
loop unrolling and data prefetching to specific parts of the code. On the other hand, the algorithm is vectorized by
columns, allowing the use of SIMD instructions for the y dimension. Results show speedups of 5x in the execution
time over a version compiled with the maximum optimizations of the Intel C/C++ compiler, maintaining the
compression ratio and the video quality (PSNR) of the original encoder based on the 3D wavelet transform. Our
experiments also show that, allowing the compiler to perform some of these optimizations (i.e. automatic code
vectorization), causes performance slowdown, demonstrating the effectiveness of our optimizations.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_vlsi05.pdf:PDF},
  keywords = {3D wavelet transform, video compression, blocking, reuse, Streaming SIMD extensions, vectorization},
}

@Misc{,
  author = {jlaragon},
  title  = {Microsoft Word - cf97-cebrian-FINAL.doc},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_cf07.pdf:PDF},
}

@InProceedings{Cebrian,
  author   = {Juan M. Cebrián and Juan L. Aragón and Stefanos Kaxiras},
  title    = {Token3D: Reducing Temperature in 3D die-stacked CMPs through Cycle-level Power Control Mechanisms},
  abstract = {Nowadays, chip multiprocessors (CMPs) are the new standard design for
a wide range of microprocessors: mobile devices (in the near future almost every 
smartphone will be governed by a CMP), desktop computers, laptop, servers, GPUs, 
APUs, etc. This new way of increasing performance by exploiting parallelism has 
two major drawbacks: off-chip bandwidth and communication latency between 
cores. 3D die-stacked processors are a recent design trend aimed at overcoming 
these drawbacks by stacking multiple device layers. However, the increase in 
packing density also leads to an increase in power density, which translates into 
thermal problems. Different proposals can be found in the literature to face these 
thermal problems such as dynamic thermal management (DTM), dynamic voltage 
and frequency scaling (DVFS), thread migration, etc. In this paper we propose the 
use of microarchitectural power budget techniques to reduce peak temperature. In 
particular, we first introduce Token3D, a new power balancing policy that takes into 
account temperature and layout information to balance the available per core power 
along other power optimizations for 3D designs. And second, we analyze a wide 
range of floorplans looking for the optimal temperature configuration. Experimental 
results show a reduction of the peak temperature of 2-26ºC depending on the 
selected floorplan.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_europar11.pdf:PDF},
  keywords = {Power budget, power tokens, DVFS, power balancing},
}

@Misc{,
  author = {jlaragon},
  title  = {Microsoft Word - VP-decay-HP-PAC07-final-v4.doc},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_hppac07.pdf:PDF},
}

@Misc{Kaisen,
  author = {Kaisen},
  title  = {Microsoft Word - IPDPS 2009-jmcg_cameraready.doc},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_ipdps09.pdf:PDF},
}

@Misc{Cebriana,
  author   = {Juan M. Cebrián, Juan L. Aragón, Stefanos Kaxiras},
  title    = {Power Token Balancing: Adapting CMPs to Power Constraints for Parallel Multithreaded Workloads},
  abstract = {2011 IEEE International Parallel & Distributed Processing Symposium},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_ipdps11.pdf:PDF},
}

@Article{Cebrian2010,
  author    = {Juan M. Cebri{\'{a}}n and Juan L. Arag{\'{o}}n and Jos{\'{e}} M. Garc{\'{\i}}a and Stefanos Kaxiras},
  journal   = {The Journal of Supercomputing},
  title     = {Leakage-efficient design of value predictors through state and non-state preserving techniques},
  year      = {2010},
  month     = {mar},
  number    = {1},
  pages     = {28--50},
  volume    = {55},
  doi       = {10.1007/s11227-010-0396-0},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cebrian_jsc11.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Misc{,
  title = {isca11.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cuesta_isca11.pdf:PDF},
}

@Misc{,
  title = {tc-2011-05-0318-1 1..14},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/cuesta_tc13.pdf:PDF},
}

@Misc{,
  title = {Microsoft Word - TACO-GC.docx},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/davari_taco15.pdf:PDF},
}

@Misc{,
  title = {bxl020 454..469},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_cj06.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_csc08.pdf:PDF},
}

@InProceedings{FernandezPascual,
  author   = {Ricardo Fernández-Pascual and José M. Garcı́a and Manuel E. Acacio and José Duato},
  title    = {A fault-tolerant directory-based cache coherence protocol for CMP architectures},
  abstract = {keeping complexity manageable, scale well to a larger
number of cores and support families of products with},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_dsn08.pdf:PDF},
}

@Misc{,
  title = {ftc-eval.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_hipc08.pdf:PDF},
}

@Misc{,
  title = {hpca13.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_hpca07.pdf:PDF},
}

@InProceedings{Fernandez0190,
  author    = {Juan Fernández and 2 Eitan Frachtenberg and Fabrizio Petrini and Kei Davis and José C. Sancho},
  title     = {Architectural Support for System Software on Large-Scale Clusters},
  year      = {0190},
  publisher = {IEEE},
  abstract  = {ware’s main components include the communication li-
brary, resource manager, parallel file system, system moni-},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_icpp04.pdf:PDF},
  keywords  = {Cluster computing, cluster operating system, features, and thus which abstract interface, should the inter- network hardware, debuggability, resource management, connection network provide to the system software design- fault tolerance. ers? We argue that the efficient and scalable implementa},
}

@InProceedings{Petrini7695,
  author    = {Juan Fernández Fabrizio Petrini and Eitan Frachtenberg and Departamento de Ingenierı́a y CCS-3 Modeling and Algorithms & Informatics and Tecnologı́a de Computadores and Los Alamos and National Laboratory},
  title     = {Monitoring and Debugging Parallel Software with BCS-MPI on Large-Scale Clusters},
  year      = {7695},
  publisher = {IEEE},
  abstract  = {Developing, monitoring and debugging parallel MPI ap-
plications is far more complicated than sequential pro-},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_ipdps05.pdf:PDF},
}

@InProceedings{FernandezPascual2012,
  author   = {Ricardo Fernández-Pascual and Alberto Ros and Manuel E. Acacio},
  title    = {Characterization of a List-Based Directory Cache Coherence Protocol for Manycore CMPs},
  year     = {2012},
  abstract = {The development of efficient and scalable cache coherence
protocols is a key aspect in the design of manycore chip multiprocessors.
In this work, we review a kind of cache coherence protocols that, despite
having been already implemented in the 90s for building large-scale com-
modity multiprocessors, have not been seriously considered in the current
context of chip multiprocessors. In particular, we evaluate a directory-
based cache coherence protocol that employs distributed simply-linked
lists to encode the information about the sharers of the memory blocks.
We compare this organization with two protocols that use centralized
sharing codes, each one having different directory memory overhead: one
of them implementing a non-scalable bit-vector sharing code and the
other one implementing a more scalable limited-pointer scheme with a
single pointer. Simulation results show that for large-scale chip multi-
processors, the protocol based on distributed linked lists obtains worse
performance than the centralized approaches. This is due, principally, to
an increase in the contention at the directory controller as a consequence
of being blocked for longer time while updating the distributed sharing
information.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_omhi14.pdf:PDF},
}

@InProceedings{Fernandez1066,
  author    = {Ricardo Fernández and José M. Garcı́a and Gregorio Bernabe and Manuel E. Acacio},
  booktitle = {Proceedings of the 13th Euromicro Conference on Parallel, Distributed and Network-Based Processing (Euromicro-PDP’05)},
  title     = {Optimizing a 3D-FWT Video Encoder for SMPs and HyperThreading Architectures},
  year      = {1066},
  publisher = {IEEE},
  abstract  = {as MPEG [20] or MPEG-4 [4] [5], as shown in [13] [8].
One of the main problems when working with the video se-},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_pdp05.pdf:PDF},
}

@InProceedings{Fernandez2003,
  author    = {Juan Fernández and 2 Eitan Frachtenberg1 Fabrizio Petrini},
  booktitle = {Proceedings of the ACM/IEEE SC2003 Conference (SC’03)},
  title     = {BCS-MPI: A New Approach in the System Software Design for Large-Scale Parallel Computers},
  year      = {2003},
  publisher = {IEEE},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_sc03.pdf:PDF},
  keywords  = {MPI, buffered coscheduling, STORM, Quadrics, system software, communication protocols, cluster com- puting, large-scale parallel computers},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_tpds08.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_tpds10.pdf:PDF},
}

@TechReport{Jose3007,
  author   = {Ricardo Jose and M. Garcı́a and Manuel E. Acacio and Fernández-Pascual jmgarcia@ditec.um.es meacacio@ditec.um.es},
  title    = {Validating a token coherence protocol for scientific workloads},
  year     = {3007},
  number   = {the},
  abstract = {the memory is physically distributed among processor nodes.
Token coherence provides a flexible framework for designing These machines add additional hardware to provide the il-
new coherence protocols which decouples performance from lusion of a single shared memory common to all processors,
correctness, easing the design of efficient coherence proto- avoiding or minimizing the problem of manual data distribu-
cols. In this work, we have implemented a coherence pro- tion. Programmers must still divide their computation into
tocol for a cc-NUMA architecture based on TokenB using parallel tasks, but all the tasks can work with a single com-
the RSIM performance simulator to validate previous claims mon dataset resident in memory. This model significantly
about token coherence performance and viability. Unlike reduces the difficulty inherent in parallel programming, es-
previous works, we have used scientific workloads to evaluate pecially for applications that exhibit dynamic communica-
the protocol performance against a directory based coher- tion patterns.
ence protocol and we have found that it provides a significant
speedup on average. Also, we have created our own simula- To provide the illusion of a shared memory while keep-
tion environment based on RSIM which can perform faster ing high performance, shared-memory machines use private
simulations of larger systems for scientific benchmarks. Our caches whose coherency must be kept through hardware co-
results show that token coherence protocols are a good alter- herence protocols. Until recently, there were two main kinds
native to directory based coherence protocols which can pro- of cache coherency protocols: snoopy protocols (which rely
vide improved performance and reduced complexity. Also, on a logical shared and totally ordered bus) and directory
we have compared the results obtained with our simulation protocols (which keep track of each copy of a data block).
environment with those obtained using GEMS for the same
benchmarks and we have found them similar, giving further The scalability of SMP machines, whose coherency proto-
credibility to both our simulation environment and GEMS. cols are based on bus snooping is limited by their need of},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_wddd06.pdf:PDF},
  keywords = {on a totally ordered network and require only point-to-point},
}

@InProceedings{Network2007,
  author    = {Interconnection Network},
  booktitle = {HiPC 2007},
  title     = {Efficient Message Management in Tiled CMP Architectures Using a Heterogeneous},
  year      = {2007},
  editor    = {S. Aluru and others},
  pages     = {133–146},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {4873},
  abstract  = {Previous studies have shown that the interconnection network
of a Chip-Multiprocessor (CMP) has significant impact on both overall
performance and energy consumption. Moreover, wires used in such in-
terconnect can be designed with varying latency, bandwidth and power
characteristics. In this work, we present a proposal for performance-and
energy-efficient message management in tiled CMPs by using a heteroge-
neous interconnect. Our proposal consists of Reply Partitioning, a tech-
nique that classifies all coherence messages into critical and short, and
non-critical and long messages; and the use of a heterogeneous intercon-
nection network comprised of low-latency wires for critical messages and
low-energy wires for non-critical ones. Through detailed simulations of 8-
and 16-core CMPs, we show that our proposal obtains average improve-
ments of 8% in execution time and 65% in the Energy-Delay2 Product
metric of the interconnect over previous works.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_hipc07.pdf:PDF},
  keywords  = {Chip-Multiprocessor, Energy-Efficient Architectures, Het- erogeneus On-Chip Interconnection Network, Parallel Scientific Applica- tions},
}

@Misc{Flores,
  author   = {Antonio Flores, Manuel E. Acacio, Juan L. Aragón},
  title    = {Address Compression and Heterogeneous Interconnects for Energy-Efficient High-Performance in Tiled CMPs},
  abstract = {37th International Conference on Parallel Processing},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_icpp08.pdf:PDF},
  keywords = {Chip-Multiprocessor, Energy-Efficient Architecture, Heterogeneus On-Chip Interconnection Network},
}

@Article{Flores2010,
  author    = {Antonio Flores and Manuel E. Acacio and Juan L. Arag{\'{o}}n},
  journal   = {Journal of Systems Architecture},
  title     = {Exploiting address compression and heterogeneous interconnects for efficient message management in tiled {CMPs}},
  year      = {2010},
  month     = {sep},
  number    = {9},
  pages     = {429--441},
  volume    = {56},
  doi       = {10.1016/j.sysarc.2010.05.006},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_jsa10.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Flores2008,
  author    = {Antonio Flores and Juan L. Arag{\'{o}}n and Manuel E. Acacio},
  journal   = {The Journal of Supercomputing},
  title     = {An energy consumption characterization of on-chip interconnection networks for tiled {CMP} architectures},
  year      = {2008},
  month     = {feb},
  number    = {3},
  pages     = {341--364},
  volume    = {45},
  doi       = {10.1007/s11227-008-0178-0},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_jsc08.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Floresa,
  author   = {Antonio Flores and Juan L. Aragón and Manuel E. Acacio and Departamento de Ingenierı́a and y Tecnologı́a and de Computadores},
  title    = {Energy-Efficient Hardware Prefetching for CMPs using Heterogeneous Interconnects},
  abstract = {In the last years high performance processor
designs have evolved toward Chip-Multiprocessor (CMP)
architectures that implement multiple processing cores on a
single die. As the number of cores inside a CMP increases, the
on-chip interconnection network will have significant impact
on both overall performance and power consumption as pre-
vious studies have shown. On the other hand, CMP designs
are likely to be equipped with latency hiding techniques like
hardware prefetching in order to reduce the negative impact
on performance that, otherwise, high cache miss rates would
lead to. Unfortunately, the extra number of network messages
that prefetching entails can drastically increase the amount
of power consumed in the interconnect. In this work, we show
how to reduce the impact of prefetching techniques in terms
of power (and energy) consumption in the context of tiled
CMPs. Our proposal is based on the fact that the wires used Figure 1. Normalized execution time and network power consumption},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_pdp10.pdf:PDF},
  keywords = {tiled chip-multiprocessor; energy-efficient archi- through global wires [3]. Wang et al. [4] reported that the},
}

@Misc{,
  title = {Sim-PowerCMP.SEC.final.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_sec07.pdf:PDF},
}

@InProceedings{Rendimiento2004,
  author = {Mejora del Rendimiento and y la},
  title  = {UNIVERSIDAD DE MURCIA Departamento de Ingeniería y Tecnología de Computadores},
  year   = {2004},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/acacio_phd03.pdf:PDF},
}

@Misc{,
  title = {lascas.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/bernabe_lascas12.pdf:PDF},
}

@Misc{,
  title = {top.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/fernandez_eg06.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/flores_tc10.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/kaxiras_isca13.pdf:PDF},
}

@InProceedings{Directory2011,
  author    = {the Directory and in Future and Many-Core CMPs},
  booktitle = {Euro-Par 2010 Workshops},
  title     = {Evaluation of Low-Overhead Organizations for},
  year      = {2011},
  editor    = {M.R. Guarracino and others},
  pages     = {87–97},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {6586},
  abstract  = {If current trends continue, today’s small-scale general-purpose
CMPs will soon be replaced by multi-core architectures integrating tens
or even hundreds of cores on-chip. Most likely, some of these many-core
CMPs will implement the hardware-managed, implicitly-addressed, co-
herent caches memory model. Cache coherence in these designs will be
probably maintained through a directory-based cache coherence proto-
col implemented in hardware. The organization of the directory structure
will be a key design point due to the requirements in area that it will
pose. In this work, we study the effects on performance, network traf-
fic and area that the use of compressed sharing codes for the directory
will have in many-core CMPs. In particular, we select two compressed
sharing codes previously proposed in the context of large-scale shared-
memory multiprocessors that have very small area requirements. Simu-
lation results of 32-core CMPs show that degradations of up to 32% in
performance and 350% in network traffic are experienced. Additionally,
since some proposals for efficient multicast support in on-chip networks
have recently appeared, we also consider the case of using this support
in combination with the compressed sharing codes. Unfortunately, we
found that multicast support is not enough to remove all the performance
degradation introduced by the compressed sharing codes and barely can
reduce network traffic.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_hppc10.pdf:PDF},
}

@Misc{,
  title = {main.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_europar09.pdf:PDF},
}

@TechReport{Frachtenberg7695,
  author    = {Eitan Frachtenberg and Fabrizio Petrini and Juan Fernandez and Salvador Coll and CCS-3 Modeling and Algorithms and Informatics Group},
  title     = {Scalable Resource Management in High Performance Computers},
  year      = {7695},
  number    = {avail-},
  abstract  = {1. Introduction},
  booktitle = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER’02)},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/frachtenberg_cluster02.pdf:PDF},
  keywords  = {Cluster Computing, Resource Management, lem of distributing control messages from a management Job Scheduling, Gang Scheduling, Parallel Architectures, node to a set of clients by implementing a special-purpose Quadrics Interconnect, I/O bypass multicast protocol. This protocol, called Reliable DataGram},
  publisher = {IEEE},
}

@Misc{EitanFrachtenberg,
  author   = {Eitan Frachtenberg, Dror G. Feitelson, Fabrizio Petrini and Juan Fernandez},
  title    = {Flexible CoScheduling: Mitigating Load Imbalance and Improving Utilization of Heterogeneous Resources},
  abstract = {Plenary Session:  Best Papers},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/frachtenberg_ipdps03.pdf:PDF},
  keywords = {Flexible CoScheduling: Mitigating Load Imbalance and Improving Utilization of Heterogeneous Resources},
}

@InProceedings{Frachtenberg2002,
  author    = {Eitan Frachtenberg and Fabrizio Petrini and Juan Fernandez and Scott Pakin and Salvador Coll},
  booktitle = {Proceedings of the IEEE/ACM SC2002 Conference (SC’02)},
  title     = {STORM: Lightning-Fast Resource Management},
  year      = {2002},
  publisher = {IEEE},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/frachtenberg_sc02.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/frachtenberg_tc06.pdf:PDF},
}

@InProceedings{Parallel1066,
  author    = {Adaptive Parallel and Job Scheduling and with Flexible and Coscheduling},
  title     = {1066 IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 16, NO. 11, NOVEMBER},
  year      = {1066},
  publisher = {IEEE},
  abstract  = {Many scientific and high-performance computing applications consist of multiple processes running on different processors
that communicate frequently. Because of their synchronization needs, these applications can suffer severe performance penalties if
their processes are not all coscheduled to run together. Two common approaches to coscheduling jobs are batch scheduling, wherein
nodes are dedicated for the duration of the run, and gang scheduling, wherein time slicing is coordinated across processors. Both work
well when jobs are load-balanced and make use of the entire parallel machine. However, these conditions are rarely met and most
realistic workloads consequently suffer from both internal and external fragmentation, in which resources and processors are left idle
because jobs cannot be packed with perfect efficiency. This situation leads to reduced utilization and suboptimal performance. Flexible
CoScheduling (FCS) addresses this problem by monitoring each job’s computation granularity and communication pattern and
scheduling jobs based on their synchronization and load-balancing requirements. In particular, jobs that do not require stringent
synchronization are identified, and are not coscheduled; instead, these processes are used to reduce fragmentation. FCS has been
fully implemented on top of the STORM resource manager on a 256-processor Alpha cluster and compared to batch, gang, and implicit
coscheduling algorithms. This paper describes in detail the implementation of FCS and its performance evaluation with a variety of
workloads, including large-scale benchmarks, scientific applications, and dynamic workloads. The experimental results show that FCS
saturates at higher loads than other algorithms (up to 54 percent higher in some cases), and displays lower response times and
slowdown than the other algorithms in nearly all scenarios.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/frachtenberg_tpds05.pdf:PDF},
}

@Article{Franco2010,
  author    = {Joaqu{\'{\i}}n Franco and Gregorio Bernab{\'{e}} and Juan Fern{\'{a}}ndez and Manuel Ujald{\'{o}}n},
  journal   = {Procedia Computer Science},
  title     = {Parallel 3D fast wavelet transform on manycore {GPUs} and multicore {CPUs}},
  year      = {2010},
  month     = {may},
  number    = {1},
  pages     = {1101--1110},
  volume    = {1},
  doi       = {10.1016/j.procs.2010.04.122},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/franco_iccs10.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Misc{Franco,
  author   = {Joaquín Franco, Gregorio Bernabé, Juan Fernández, Manuel E. Acacio},
  title    = {A Parallel Implementation of the 2D Wavelet Transform Using CUDA},
  abstract = {Parallel, Distributed and Network-based Processing},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/franco_pdp09.pdf:PDF},
  keywords = {2D fast wavelet transform, parallel programming, multicore processor, CUDA, NVIDIA Tesla},
}

@Misc{Author,
  author   = {Author},
  title    = {Title},
  abstract = {Subject},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/gaona_europar09.pdf:PDF},
}

@Article{Gaona2013,
  author    = {Epifanio Gaona and J. Rub{\'{e}}n Titos-Gil and Juan Fern{\'{a}}ndez and Manuel E. Acacio},
  journal   = {The Journal of Supercomputing},
  title     = {Selective dynamic serialization for reducing energy consumption in hardware transactional memory systems},
  year      = {2013},
  month     = {dec},
  number    = {2},
  pages     = {914--934},
  volume    = {68},
  doi       = {10.1007/s11227-013-1072-y},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/gaona_jsc14.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Gaona2015,
  author    = {Epifanio Gaona and Jos{\'{e}} L. Abell{\'{a}}n and Manuel E. Acacio},
  journal   = {The Journal of Supercomputing},
  title     = {Fast and efficient commits for Lazy-Lazy hardware transactional memory},
  year      = {2015},
  month     = {sep},
  number    = {12},
  pages     = {4305--4326},
  volume    = {71},
  doi       = {10.1007/s11227-015-1523-8},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/gaona_jsc15.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Misc{GaonaRamirez,
  author   = {Epifanio Gaona-Ramírez, Rubén Titos-Gil, Juan Fernández, Manuel E. Acacio},
  title    = {Characterizing Energy Consumption in Hardware Transactional Memory Systems},
  abstract = {2010 22nd International Symposium on Computer Architecture and High Performance Computing},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/gaona_sbacpad10.pdf:PDF},
  keywords = {Hardware Transactional Memory (HTM), version management, conflict detection, lazy-lazy, eager-eager},
}

@InProceedings{Garcia2005,
  author    = {Pablo E. Garćıa and Juan Fernández and Fabrizio Petrini and José M. Garćıa},
  booktitle = {EuroPVM/MPI 2005},
  title     = {Assessing MPI Performance on QsNetII},
  year      = {2005},
  editor    = {B. Di and Martino et al.},
  pages     = {399–406},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {3666},
  abstract  = {To evaluate the communication capabilities of clusters, we
must take into account not only the interconnection network but also
the system software. In this paper, we evaluate the communication ca-
pabilities of a cluster based on dual-Opteron SMP nodes interconnected
with QsNetII . In particular, we study the raw network performance, the
ability of MPI to overlap computation and communication, and the ap-
propriateness of the local operating systems to support parallel process-
ing. Experimental results show a stable system with a really efficient
communication subsystem which is able to deliver 875 MB/s unidirec-
tional bandwidth, 1.6 µsec unidirectional latency, and up to 99.5% CPU
availability while communication is in progress.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/garcia_europvmmpi05.pdf:PDF},
}

@Misc{,
  title = {TACO0804-25.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/garcia_hipeac12.pdf:PDF},
}

@InProceedings{Server,
  author   = {Chip-Multiprocessors for Server and Consolidation},
  title    = {Energy-Efficient Cache Coherence Protocols in},
  abstract = {As the number of cores in a chip increases, system is meant to be used in a consolidated environment,
power consumption is becoming a major constraint in the the coherence protocol should take advantage of the special
design of chip multiprocessors. At the same time, server characteristics of such an environment in order to improve
consolidation is gaining importance to take advantage of such
a number of cores. Our goal is to alleviate this constraint by performance and reduce power consumption.
reducing the power consumption of chip multiprocessors used Typically, there are two kinds of data in a VM: private
for consolidated workloads by means of the cache coherence data to the VM and data shared between VMs. The first one
protocol. For this, we statically divide the chip in areas, is only accessed by a single VM, and therefore, there is no
which allows us to reduce the directory overhead needed to use in keeping coherence information beyond the limits of
support coherence and to reduce the network traffic. This
translates into less power consumption without performance that VM.
degradation. Cache coherence is maintained per area and On the other hand, data shared between VMs is expected
pointers are used to link the areas, thereby achieving isolation to be read-only data which are being shared because the
among virtual machines and savings in memory requirements. hypervisor has applied memory deduplication [4, 5]. Dedu-
Additionally, the coherence protocol dynamically selects one plicated memory pages are read-only memory pages, with
node per area as responsible for providing the data on a cache
miss, thus lessening the average cache miss latency and the identical contents, that are present in the virtual memory
traffic among areas. Compared to a highly-optimized directory of more than one single VM. The hypervisor detects these
implementation, the leakage power consumption is reduced by identical pages and a single physical page is allocated in
54% and the dynamic power consumption of the caches and the physical memory. If a deduplicated memory page is written,
network-on-chip by up to 38% for a 64-tile chip multiprocessor a copy-on-write policy is used and a new page is allocated
with 4 virtual machines, showing no performance degradation.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/garcia_icpp11.pdf:PDF},
}

@Misc{,
  title = {TACO0804-25.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/garcia_taco12.pdf:PDF},
}

@Misc{,
  title = {kaxiras_hpdc15.pdf},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/kaxiras_hpdc15.pdf:PDF},
}

@Misc{,
  author = {stefanos},
  title  = {ACM FrameMaker Template for SIG Site},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/kaxiras_socc12.pdf:PDF},
}

@InProceedings{Moody2003,
  author    = {Adam Moody and 2 Juan Fernandez2 Fabrizio Petrini},
  booktitle = {Proceedings of the ACM/IEEE SC2003 Conference (SC’03)},
  title     = {Scalable NIC-based Reduction on Large-scale Clusters},
  year      = {2003},
  publisher = {IEEE},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/moody_sc03.pdf:PDF},
}

@Misc{Negi,
  author   = {Anurag Negi, Rubén Titos-Gil, Manuel E. Acacio, José M. García, Per Stenstrom},
  title    = {The Impact of Non-coherent Buffers on Lazy Hardware Transactional Memory Systems},
  abstract = {2011 IEEE International Parallel & Distributed Processing Symposium},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/negi_apdcm11.pdf:PDF},
}

@Misc{Negia,
  author   = {Anurag Negi, Rubén Titos-Gil, Manuel E. Acacio, José M. García, Per Stenstrom},
  title    = {Eager Meets Lazy: The Impact of Write-Buffering on Hardware Transactional Memory},
  abstract = {2011 International Conference on Parallel Processing},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/negi_icpp11.pdf:PDF},
  keywords = {hardware transactional memory, multicores},
}

@Misc{,
  title = {paper.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ostby_rapido10.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/petoumenos_arcs10.pdf:PDF},
}

@InProceedings{Petrini7695a,
  author    = {Fabrizio Petrini and Juan Fernandez and Eitan Frachtenberg and Salvador Coll},
  title     = {Scalable Collective Communication on the ASCI Q Machine},
  year      = {7695},
  publisher = {IEEE},
  abstract  = {Another issue that has often been neglected is the per-
formance and scalability of the system software on large-},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/petrini_hoti03.pdf:PDF},
}

@TechReport{Petrini1997,
  author   = {Fabrizio Petrini and Adam Moody and Juan Fernández and Eitan Frachtenberg and Dhabaleswar K. Panda},
  title    = {NIC-based Reduction Algorithms for Large-scale Clusters},
  year     = {1997},
  number   = {the},
  abstract = {Efficient algorithms for reduction operations across a group of pro-
cesses are crucial for good performance in many large-scale, parallel scientific
applications. While previous algorithms limit processing to the host CPU, we
utilize the programmable processors and local memory available on modern clus-
ter network interface cards (NICs) to explore a new dimension in the design of re-
duction algorithms. In this paper, we present the benefits and challenges, design
issues and solutions, analytical models, and experimental evaluations of a fam-
ily of NIC-based reduction algorithms. Performance and scalability evaluations
were conducted on the ASCI Linux Cluster (ALC), a 960-node, 1920-processor
machine at Lawrence Livermore National Laboratory, which uses the Quadrics
QsNet interconnect. We find NIC-based reductions on modern interconnects to
be more efficient than host-based implementations in both scalability and con-
sistency. In particular, at large-scale—1812 processes—NIC-based reductions of
small integer and floating-point arrays provided respective speedups of 121% and
39% over the host-based, production-level MPI implementation.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/petrini_ijhpcn06.pdf:PDF},
  keywords = {cluster computing; reduce; allreduce; Quadrics QsNet; NIC-based operations; collective communication},
}

@Misc{,
  title = {top2.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/petrini_ipdps07.pdf:PDF},
}

@Misc{Authora,
  author   = {Author},
  title    = {Title},
  abstract = {Subject},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_appt09.pdf:PDF},
}

@InProceedings{Ros,
  author   = {Alberto Ros and Manuel E. Acacio and José M. Garcı́a and Departamento de Ingenierı́a and y Tecnologı́a and de Computadores},
  title    = {Scalable Directory Organization for Tiled CMP Architectures},
  abstract = {a directory-based protocol, since protocols based on broad-
casting requests are not power-efficient due to the tremen-},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_cdes08.pdf:PDF},
  keywords = {Tiled chip multiprocessors, cache coherence, di- same sharing information is to duplicate the tags of all pri- rectory organization, scalability, implicit replacements. vate caches. This scheme has been recently used in CMPs as},
}

@InProceedings{Ros2006,
  author   = {Alberto Ros and Manuel E. Acacio and José M. Garcı́a and a.ros@ditec.um.es meacacio@ditec.um.es jmgarcia@ditec.um.es},
  title    = {An Efficient Cache Design for Scalable Glueless Shared-Memory Multiprocessors},
  year     = {2006},
  abstract = {Keywords
Traditionally, cache coherence in large-scale shared-memory Glueless shared-memory multiprocessors, cache coherence,
multiprocessors has been ensured by means of a distributed L2 cache, directory structure, memory wall
directory structure stored in main memory. In this way,
the access to main memory to recover the sharing status of
the block is generally put in the critical path of every cache 1. INTRODUCTION
miss, increasing its latency. Considering the ever-increasing Workload and technology trends point toward highly in-
distance to memory, these cache coherence protocols are far tegrated “glueless” designs [12]. These designs integrate
from being optimal from the perspective of performance. On the processor’s core, caches, network interface and coher-
the other hand, shared-memory multiprocessors formed by ence hardware onto a single die. It allows to directly con-
connecting chips that integrate the processor, caches, coher- nect these highly integrated nodes using a high-bandwidth
ence logic, switch and memory controller through a low-cost, low-latency point-to-point network leading to glueless multi-
low-latency point-to-point network (glueless shared-memory processors. Taking advantage of ever faster interconnection
multiprocessors) are a reality. network, more research efforts must be carried out in low-},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_cf06.pdf:PDF},
}

@InProceedings{SharedMemory3007,
  author   = {Scalable Shared-Memory and Multiprocessors},
  title    = {A Novel Lightweight Directory Architecture for},
  year     = {3007},
  abstract = {There are two important hurdles that restrict the scalability
of directory-based shared-memory multiprocessors: the directory mem-
ory overhead and the long L2 miss latencies due to the indirection intro-
duced by the accesses to directory information, usually stored in main
memory. This work presents a lightweight directory architecture aimed
at facing these two important problems. Our proposal takes advantage
of the temporal locality exhibited by the accesses to the directory in-
formation and on-chip integration to design a directory protocol with
the best characteristics of snoopy protocols. The lightweight directory
architecture removes the directory structure from main memory and it
stores directory information in the L2 cache avoiding in most cases the
access to main memory. The proposed architecture is evaluated based on
extensive execution-driven simulations of a 32-node cc-NUMA multipro-
cessor. Results demonstrate that the lightweight directory architecture
achieves better performance than a non-scalable full-map directory, with
a very significant reduction on directory memory overhead.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_europar05.pdf:PDF},
}

@InProceedings{Performance3010,
  author   = {Performance and Scalability and in Shared-Memory},
  title    = {Direct Coherence: Bringing Together},
  year     = {3010},
  abstract = {Traditional directory-based cache coherence protocols suffer
from long-latency cache misses as a consequence of the indirection intro-
duced by the home node, which must be accessed on every cache miss
before any coherence action can be performed. In this work we present a
new protocol that moves the role of storing up-to-date coherence infor-
mation (and thus ensuring totally ordered accesses) from the home node
to one of the sharing caches. Our protocol allows most cache misses to be
directly solved from the corresponding remote caches, without requiring
the intervention of the home node. In this way, cache miss latencies are
reduced. Detailed simulations show that this protocol leads to improve-
ments in total execution time of 8% on average over a highly optimized
MOESI directory-based protocol.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_hipc07.pdf:PDF},
}

@InProceedings{Ros4244,
  author    = {Alberto Ros and Marcelo Cintra and Manuel E. Acacio and José M. Garcı́a and ∗ Departamento de Ingenierı́a y Tecnologı́a de Computadores and Universidad de Murcia and 30100 Murcia (Spain)},
  title     = {Distance-Aware Round-Robin Mapping for Large NUCA Caches},
  year      = {4244},
  publisher = {IEEE},
  abstract  = {In many-core architectures, memory blocks are One important decision when designing tiled CMPs is how
commonly assigned to the banks of a NUCA cache by following to organize the last-level on-chip cache, since cache misses
a physical mapping. This mapping assigns blocks to cache banks at this level result in long-latency off-chip accesses. The two
in a round-robin fashion, thus neglecting the distance between
the cores that most frequently access every block and the common ways of organizing this cache level, e.g. the L2 cache,},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_hipc09.pdf:PDF},
}

@Misc{,
  title = {hipc10.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_hipc10.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_hpca15.pdf:PDF},
}

@InProceedings{Rosa,
  author   = {Alberto Ros and Blas Cuesta and Marı́a E. Gómez and Antonio Robles and José Duato},
  title    = {Temporal-Aware Mechanism to Detect Private Data in Chip Multiprocessors},
  abstract = {Most of the data referenced by sequential and messages. Nevertheless, they require a directory structure
parallel applications running in current chip multiprocessors whose size grows exponentially with the system size. Again,
are referenced by only one thread and can be considered some works have addressed this problem [4], [5], [6].
as private data. A lot of recent proposals leverage this ob-
servation to improve many aspects of chip multiprocessors, Another important design aspect of CMPs is the last-level
such as reducing coherence overhead or the access latency to cache (LLC) organization. An NUCA (Non-Uniform Cache
distributed caches. The effectiveness of those proposals depend Architecture) organization can reduce the number of off-
to a large extent on the amount of detected private data. chip accesses [7]. Since the average access latency to NUCA
However, the mechanisms proposed so far do not consider caches increases with the number of cores some works have
thread migration and the private use of data within different
application phases. As a result, a considerable amount of data also addressed this inefficiency [8], [9], [10].
is not detected as private. In order to make this detection A common technique used to improve coherence proto-
more accurate and reaching more significant improvements, cols and the organization of the LLC is classifying data ac-
we propose a mechanism that is able to account for both cessed by applications into private (i.e., accessed by only one
thread migration and private data within application phases. thread) and shared (i.e., accessed by two or more threads)
Simulation results for 16-core systems show that, thanks to our
mechanism, the average number of pages detected as private [3], [5], [10], [11], [12], [13], [14], [15], [16]. The key
significantly increases from 43% in previous proposals up to observation behind these works is that a significant fraction
74% in ours. Finally, when our detection mechanism is used of the memory blocks referenced during the execution of
to deactivate the coherence for private data in a directory sequential and parallel applications is private. Hence, they
protocol, our proposal improves execution time by 13% with implement mechanisms to detect such private blocks in order
respect to previous proposals. to handle them in a more efficient and fast way. For instance,},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_icpp13.pdf:PDF},
  keywords = {Cache coherence; private-shared data; TLB-to- Cuesta et al. [5] propose to prevent directory information TLB transfers; TLB decay; coherence optimizations of private blocks from being included in the directory},
}

@InProceedings{Ros3010,
  author   = {Alberto Ros and Manuel E. Acacio and José M. Garcı́a and Departamento de Ingenierı́a and y Tecnologı́a and de Computadores},
  title    = {DiCo-CMP: Efficient Cache Coherency in Tiled CMP Architectures},
  year     = {3010},
  abstract = {multiprocessors (CMPs) [24] have important advantages
over very wide-issue out-of-order superscalar processors.},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_ipdps08.pdf:PDF},
}

@InProceedings{Murcia,
  author   = {University of Murcia and Uppsala Universitet and aros@ditec.um.es alexandra.jimborean@it.uu.se},
  title    = {A Dual-Consistency Cache Coherence Protocol Alberto Ros Alexandra Jimborean},
  abstract = {Weak memory consistency models can maximize Another source of inefficiency of traditional protocols stems
system performance by enabling hardware and compiler opti- from not taking advantage of applications’ behavior, thus
mizations, but increase programming complexity since they do missing potential performance improvements. To exploit this
not match programmers’ intuition. The design of an efficient
system with an intuitive memory model is an open challenge. opportunity, numerous proposals revolve around identifying},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_ipdps15.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_isca15.pdf:PDF},
}

@Misc{,
  title = {islp312-ros.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_islped12.pdf:PDF},
}

@InProceedings{,
  author = {sharing with colleagues.},
  title  = {This article appeared in a journal published by Elsevier. The attached copy is furnished to the author for internal non-commercial research and education use, including for instruction at the authors institution},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_jpdc08.pdf:PDF},
}

@Article{Ros2010,
  author    = {Alberto Ros and Manuel E. Acacio and Jos{\'{e}} M. Garc{\'{\i}}a},
  journal   = {Journal of Systems Architecture},
  title     = {A scalable organization for distributed directories},
  year      = {2010},
  month     = {feb},
  number    = {2-3},
  pages     = {77--87},
  volume    = {56},
  doi       = {10.1016/j.sysarc.2009.11.006},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_jsa10.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_jsc15.pdf:PDF},
}

@Misc{Rosb,
  author   = {Alberto Ros, Blas Cuesta, María Engracia Gómez, Antonio Robles, José Duato},
  title    = {Cache Miss Characterization in Hierarchical Large-Scale Cache-Coherent Systems},
  abstract = {2012 10th IEEE International Symposium on Parallel and Distributed Processing with Applications},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_m2a212.pdf:PDF},
  keywords = {Characterization, extended cache coherence, directory protocols, scalability},
}

@InProceedings{Ros2012,
  author   = {Alberto Ros and Stefanos Kaxiras and Department of Computer and Engineering Department and of Information and Technology},
  title    = {Complexity-Effective Multicore Coherence},
  year     = {2012},
  abstract = {1. INTRODUCTION
Much of the complexity and overhead (directory, state bits, “For any given memory location, at any given moment in},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_pact12.pdf:PDF},
  keywords = {hierarchy organization with private L1(/L2) caches and a shared Last-Level-Cache (LLC). Our motivation is to sim},
}

@Misc{,
  title = {parmaditam15.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_parmaditam15.pdf:PDF},
}

@InProceedings{2007,
  author = {0�},
  year   = {2007},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_pdc10.pdf:PDF},
}

@InProceedings{Rosc,
  author   = {Alberto Ros and Ricardo Fernández-Pascual and Manuel E. Acacio and Universidad de Murcia and Spain},
  title    = {Using Heterogeneous Networks to Improve Energy Efficiency in Direct Coherence Protocols for Many-Core CMPs},
  abstract = {Direct coherence protocols have been recently building blocks (tiles) connected over an on-chip switched
proposed as an alternative to directory-based protocols to direct network [3]. Each tile contains at least one processing
keep cache coherence in many-core CMPs. Differently from core, caches and a connection to the on-chip network.
directory-based protocols, in direct coherence the responsible
for providing the requested data in case of a cache miss (i.e., the These tiled architectures have been claimed to provide a
owner cache) is also tasked with keeping the updated directory scalable solution for managing the design complexity, and
information and serializing the different accesses to the block effectively using the resources available in advanced VLSI
by all cores. This way, these protocols send requests directly technologies.
to the owner cache, thus avoiding the indirection caused by As the number of cores increases, the cache coherence
accessing a separate directory (usually in the home node). A
hints mechanism ensures a high hit rate when predicting the protocol turns into a key element in the performance and
current owner of a block for sending requests, but at the price power consumption of the whole CMP. Directory-based
of significantly increasing network traffic, and consequently, cache coherence protocols have been typically employed
energy consumption. In this work, we show how using a in systems with direct networks, as tiled CMPs are. The
heterogeneous interconnection network composed of two kinds directory structure is distributed between the last-level cache
of links is enough to drastically reduce the energy consumed
by hint messages, obtaining significant improvements in energy banks (L2 in this work), usually included into the tags
efficiency. portion [4]. In this way, each tile keeps the sharing infor-},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_sbacpad12.pdf:PDF},
  keywords = {Cache coherence, heterogeneous networks, direct},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_tc11.pdf:PDF},
}

@Misc{,
  title = {ascib.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_tc15.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ros_tpds10.pdf:PDF},
}

@InProceedings{Sanchez2000,
  author   = {Daniel Sánchez and Juan L. Aragón and José M. Garcı́a},
  title    = {Extending SRT for Parallel Applications in Tiled-CMP Architectures},
  year     = {2000},
  abstract = {disappear by themselves. The differences between them are},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_dpdns09.pdf:PDF},
}

@InProceedings{Sanchez4244,
  author    = {Daniel Sánchez and Juan L. Aragón and José M. Garcı́a},
  title     = {A Log-Based Redundant Architecture for Reliable Parallel Computation},
  year      = {4244},
  publisher = {IEEE},
  abstract  = {arrays, such as caches or RAM. However, ECC cannot be},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_hipc10.pdf:PDF},
}

@Misc{,
  title = {untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_iolts11.pdf:PDF},
}

@Article{Sanchez2011,
  author    = {Daniel S{\'{a}}nchez and Juan L. Arag{\'{o}}n and Jos{\'{e}} M. Garc{\'{\i}}a},
  journal   = {The Journal of Supercomputing},
  title     = {A fault-tolerant architecture for parallel applications in tiled-{CMPs}},
  year      = {2011},
  month     = {aug},
  number    = {3},
  pages     = {997--1023},
  volume    = {61},
  doi       = {10.1007/s11227-011-0670-9},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_jsc11.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Sanchez,
  author   = {Daniel Sánchez and Juan L. Aragón and José M. Garcı́a and Departamento de Ingenierı́a and y Tecnologı́a and de Computadores},
  title    = {Evaluating Dynamic Core Coupling in a Scalable Tiled-CMP Architecture},
  abstract = {However, due to the raise of the number of tran-
sistors per chip, the failure ratio is increasing more},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sanchez_wddd08.pdf:PDF},
}

@InProceedings{Carlos7695,
  author    = {José Carlos and Sancho Fabrizio and Petrini Greg and Johnson Juan and Fernández and Eitan Frachtenberg},
  title     = {On the Feasibility of Incremental Checkpointing for Scientific Computing},
  year      = {7695},
  publisher = {IEEE},
  abstract  = {tion. Moreover, the increasing complexity of these clus-
ters means that the system may still fail despite the},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/sancho_ipdps04.pdf:PDF},
  keywords  = {Fault-tolerance, Checkpointing, Auto- bility platforms, system availability and efficiency are},
}

@InProceedings{Singh2020,
  author    = {Sawan Singh and Alexandra Jimborean and Alberto Ros},
  booktitle = {Proceedings of the {ACM} International Conference on Parallel Architectures and Compilation Techniques},
  title     = {Regional Out-of-Order Writes in Total Store Order},
  year      = {2020},
  month     = {sep},
  publisher = {{ACM}},
  doi       = {10.1145/3410463.3414645},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/ssingh_pact20.pdf:PDF},
}

@InProceedings{Approaches,
  author = {Hardware Approaches and to and Transactional Memory and in Chip and Multiprocessors},
  title  = {Chapter},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_bc15.pdf:PDF},
}

@Misc{,
  title = {Untitled},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_hipc08.pdf:PDF},
}

@Misc{,
  title = {ics2011.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_ics11.pdf:PDF},
}

@InProceedings{Titos,
  author   = {Rubén Titos and Manuel E. Acacio and José M. Garcı́a and Departamento de Ingenierı́a and y Tecnologı́a and de Computadores},
  title    = {Speculation-Based Conflict Resolution in Hardware Transactional Memory},
  abstract = {transaction. A conflict appears when two or more concurrent
transactions access the same location and at least one of the},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_ipdps09.pdf:PDF},
}

@InProceedings{Gil2008,
  author    = {J. Ruben Titos Gil and Manuel E. Acacio Sanchez and Jose M. Garcia Carrasco},
  booktitle = {16th Euromicro Conference on Parallel, Distributed and Network-Based Processing ({PDP} 2008)},
  title     = {Characterization of Conflicts in Log-Based Transactional Memory ({LogTM})},
  year      = {2008},
  month     = {feb},
  publisher = {{IEEE}},
  doi       = {10.1109/pdp.2008.63},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_pdp08.pdf:PDF},
}

@Article{TitosGil2014,
  author    = {Ruben Titos-Gil and Anurag Negi and Manuel E. Acacio and Jose M. Garcia and Per Stenstrom},
  journal   = {{IEEE} Transactions on Parallel and Distributed Systems},
  title     = {{ZEBRA}: Data-Centric Contention Management in Hardware Transactional Memory},
  year      = {2014},
  month     = {may},
  number    = {5},
  pages     = {1359--1369},
  volume    = {25},
  doi       = {10.1109/tpds.2013.262},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/titos_tpds14.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Trivino,
  author   = {Francisco Triviño and Francisco J. Andujar and Francisco J. Alfaro and José L. Sánchez},
  title    = {Self-Related Traces: An Alternative to Full-System Simulation for NoCs},
  abstract = {portant aspects involved in a NoC with high accuracy. Usu-},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/trivino_hpcs11.pdf:PDF},
  keywords = {Network-on-Chip, Multicore, Simula- in GEMS. Particularly, we have added Noxim [2], our target tion, Full-System, Trace-Driven},
}

@Misc{,
  title = {paper-rev1.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/valls_jsc15.pdf:PDF},
}

@Misc{,
  title = {paper.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/valls_jsc15b.pdf:PDF},
}

@InProceedings{Valls4503,
  author   = {Joan J. Valls and Alberto Ros and Julio Sahuquillo and María E. Gómez and José Duato},
  title    = {PS-Dir: A Scalable Two-Level Directory Cache},
  year     = {4503},
  abstract = {DIRECTORY ORGANIZATION miss},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/valls_pact12.pdf:PDF},
  keywords = {Multicore, cache coherence, directory protocol, same fields as a typical directory cache but with much lower two-level directory, private/shared blocks},
}

@Misc{,
  title = {paper.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/valls_pact13.pdf:PDF},
}

@Misc{,
  title = {paper.dvi},
  file  = {:/run/media/carbon/Work/UMU/caps-web/pdfs/valls_pdp15.pdf:PDF},
}

@InProceedings{Villa2005,
  author    = {Francisco J. Villa and Manuel E. Acacio and José M. García},
  booktitle = {HPCC 2005},
  title     = {Memory Subsystem Characterization in a 16-Core Snoop-Based Chip-Multiprocessor Architecture},
  year      = {2005},
  editor    = {L.T. Yang and others},
  pages     = {223–232},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {3726},
  abstract  = {In this paper we present an exhaustive evaluation of the
memory subsystem in a chip-multiprocessor (CMP) architecture com-
posed of 16 cores. The characterization is performed making use of a new
simulator that we have called DCMPSIM and extends the Rice Simula-
tor for ILP Multiprocessors (RSIM) with the functionality required to
model a contemporary CMP in great detail.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_hpcc05.pdf:PDF},
  keywords  = {Dense chip-multiprocessors, memory subsystem, snoop-based cache-coherence, high-performance interconnection networks},
}

@InProceedings{Villa2004,
  author    = {Francisco J. Villa and Manuel E. Acacio and José M. Garcı́a},
  booktitle = {ICCS 2004},
  title     = {On the Evaluation of x86 Web Servers Using Simics: Limitations and Trade-Offs},
  year      = {2004},
  editor    = {M. Bubak and others},
  pages     = {541–544},
  publisher = {Springer},
  series    = {LNCS},
  volume    = {3036},
  abstract  = {In this paper, we present our first experiences using Simics, a simulator
which allows full-system simulation of multiprocessor architectures. We carry out
a detailed performance study of a static web content server, showing how changes
in some architectural parameters affect final performance. The results we have
obtained corroborate the intuition of increasing performance of a dual-processor
web server opposite to a single-processor one, and at the same time, allow us to
check out Simics limitations. Finally, we compare these results with those that are
obtained on real machines.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_iccs04.pdf:PDF},
}

@InProceedings{Villa3008,
  author   = {Francisco J. Villa and Manuel E. Acacio and José M. García and Departamento de Ingeniería and y Tecnología and de Computadores},
  title    = {On the Evaluation of Dense Chip-Multiprocessor Architectures},
  year     = {3008},
  abstract = {Chip-multiprocessors (CMPs) have been revealed CPU 1 CPU 2 CPU N},
  file     = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_icsamos06.pdf:PDF},
}

@InProceedings{Villa0576,
  author    = {Oreste Villa and Daniele Paolo Scarpazza and Fabrizio Petrini and Juan Fernández Peinador},
  booktitle = {choices involved in mapping a BFS algorithm on the Cell The research described in this paper was conducted under the Laboratory BE. The choice of a conceptually simple algorithm such as Directed Research and Development Program for the Data Intensive Com- the BFS allows for a complete, in-depth analysis. puting Initiative at Pacific Northwest National Laboratory, a multi-program This paper provides three primary contributions. (1) A national laboratory operated by Battelle for the U.S. Department of Energy under Contract DEAC0576RL01830. detailed description of the BFS graph exploration algorithm},
  title     = {Challenges in Mapping Graph Exploration Algorithms on Advanced Multi-core Processors},
  year      = {0576},
  publisher = {IEEE},
  abstract  = {as a basic building block for high performance clusters and
supercomputers.},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_ipdps07.pdf:PDF},
}

@InProceedings{&2006,
  author = {! } # $" %'&( *) and /0 and  and &!= and @?81& % A :CBED and %AE and ( 2F7 7G. #{ HI and J&1%F  K B},
  title  = {JCS&T Vol. 6 No. 1 April},
  year   = {2006},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_jcst06.pdf:PDF},
}

@InProceedings{2003,
  author = {Evaluación de un servidor web multiprocesador and mediante Simics},
  title  = {XIV JORNADAS DE PARALELISMO—LEGANÉS, SEPTIEMBRE},
  year   = {2003},
  file   = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_jornadas03.pdf:PDF},
}

@Article{Villa2005a,
  author    = {F.J. Villa and M.E. Acacio and J.M. Garc{\'{\i}}a},
  journal   = {Journal of Systems Architecture},
  title     = {Evaluating {IA}-32 web servers through simics: a practical experience},
  year      = {2005},
  month     = {apr},
  number    = {4},
  pages     = {251--264},
  volume    = {51},
  doi       = {10.1016/j.sysarc.2004.09.003},
  file      = {:/run/media/carbon/Work/UMU/caps-web/pdfs/villa_jsa05.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Comment{jabref-meta: databaseType:bibtex;}
